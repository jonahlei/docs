{
    "openapi": "3.1.0",
    "info": {
        "title": "创建上下文缓存 API",
        "description": "创建上下文缓存，获得缓存 `id` 字段后，在 [ContextChatCompletions - 上下文缓存对话](https://www.volcengine.com/docs/82379/1346560) 中使用。API 使用教程请参见 [上下文缓存（Context API）概述](https://www.volcengine.com/docs/82379/1398933)。",
        "version": "1.0.0"
    },
    "tags":[],
    "paths": {
        "/context/create": {
            "post": {
                "summary": "创建上下文缓存",
                "deprecated": false,
                "description": "该接口用于创建上下文缓存，返回的缓存 ID 可用于后续的上下文缓存对话。",
                "security": [
                    {
                        "ApiKeyAuth": []
                    }
                ],
                "requestBody": {
                    "required": true,
                    "content": {
                        "application/json": {
                            "schema": {
                                "$ref": "#/components/schemas/CreateContextRequest"
                            }
                        }
                    }
                },
                "responses": {
                    "200": {
                        "description": "成功创建上下文缓存",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "$ref": "#/components/schemas/CreateContextResponse"
                                }
                            }
                        }
                    }
                }
            }
        }
    },
    "components": {
        "securitySchemes": {
            "ApiKeyAuth": {
                "type": "http",
                "scheme": "bearer",
                "bearerFormat": "API Key",
                "description": "使用 API Key 进行鉴权"
            }
        },
        "schemas": {
            "CreateContextRequest": {
                "type": "object",
                "required": [
                    "model",
                    "messages",
                    "mode"
                ],
                "properties": {
                    "model": {
                        "type": "string",
                        "description": "大模型推理服务的接入点 ID（Endpoint id）。通过文档 [创建推理接入点](https://www.volcengine.com/docs/82379/1099522)，您完成推理服务接入点创建，并根据业务需求配置大模型、购买方式、计费类型等信息。",
                        "example": "ep-xxx"
                    },
                    "messages": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "role": {
                                    "type": "string",
                                    "description": "消息的角色，如 'system' 或 'user'"
                                },
                                "content": {
                                    "type": "string",
                                    "description": "消息的内容"
                                }
                            }
                        },
                        "description": "由对话组成的消息列表。注意：Context Initial Messages，如系统人设，背景信息等，用户自定义的信息。这个信息用于初始化或希望服务在缓存中存储的信息，需拼接在 chat 前。",
                        "example": [
                            {
                                "role": "system",
                                "content": "you are a helpful asssistant"
                            },
                            {
                                "role": "user",
                                "content": "hello"
                            }
                        ]
                    },
                    "mode": {
                        "type": "string",
                        "description": "上下文缓存的类型，详细见 [上下文缓存（Context API）概述](https://www.volcengine.com/docs/82379/1398933)。\n- `session` ：Session 缓存，支持的模型请参见 [支持的模型](https://www.volcengine.com/docs/82379/1396491#5f0f3750)。\n- `common_prefix` ：前缀缓存，支持的模型请参见 [模型列表](https://www.volcengine.com/docs/82379/1396490#5f0f3750)。",
                        "example": "session"
                    },
                    "ttl": {
                        "type": "integer",
                        "description": "过期时长，单位为秒。信息在创建后即开始计时，每次使用则重置为 0。计时超过 ttl，信息会被从缓存中删除。每次调用 chat 均根据 ttl 更新过期时间。过期时间可以设置的范围在 1 小时到 7 天，即 [3600, 604800]。",
                        "default": 86400,
                        "example": 86400
                    },
                    "truncation_strategy": {
                        "type": "object",
                        "description": "控制历史上下文窗口。不设置会根据推理接入点调用的模型自动判断使用哪种模式的 Session 缓存。当 `mode` 字段设置为 `session`，该字段可设置；当 `mode` 字段设置为 `common_prefix`，该字段不可设置。",
                        "properties": {
                            "type": {
                                "type": "string",
                                "description": "用户截断的策略，对话会综合最近存储的历史 token 数、模型大小和 chat 时的 `max_tokens` 进行截断。\n- `last_history_tokens`：使用 [last_history_tokens 模式](https://www.volcengine.com/docs/82379/1396491#a14e038d)，取决于使用的模型支持哪种 Session 缓存。\n- `rolling_tokens`：使用 [rolling_tokens 模式](https://www.volcengine.com/docs/82379/1396491#dc052059)，取决于使用的模型支持哪种 Session 缓存。",
                                "example": "last_history_tokens"
                            },
                            "last_history_tokens": {
                                "type": "integer",
                                "description": "`type` 设置为 `last_history_tokens` 时，进行设置。缓存存储的最大 token 数，触发该上限将根据模型上下文大小对缓存内容进行截断，截断顺序按照时间由远及近。",
                                "default": 4096,
                                "example": 4096
                            },
                            "rolling_tokens": {
                                "type": "boolean",
                                "description": "`type` 设置为 `rolling_tokens` 时，进行设置。在 context 历史消息长度接近模型上下文时，是否自动对历史上下文进行裁剪。\n- `false`：在历史消息长度超过上下文长度时模型会停止输出（`finish_reason` 为 `length` 时）。\n- `true`：在历史消息长度接近上下文长度时模型自动按照先进先出的顺序，删除定量（4k）的内容，为新对话内容腾挪缓存空间；同时对缓存中的信息进行重新计算和读入，保障内容理解一致性。具体的计算逻辑，请参见 [rolling_tokens 模式](https://www.volcengine.com/docs/82379/1396491#dc052059)。",
                                "default": true,
                                "example": true
                            }
                        }
                    }
                }
            },
            "CreateContextResponse": {
                "type": "object",
                "properties": {
                    "id": {
                        "type": "string",
                        "description": "您创建的上下文缓存 ID，在后续创建带缓存的 [ContextChatCompletions - 上下文缓存对话](https://www.volcengine.com/docs/82379/1346560) 需要使用。",
                        "example": "ctx-xxx"
                    },
                    "model": {
                        "type": "string",
                        "description": "您的推理接入点 ID。",
                        "example": "ep-xxx"
                    },
                    "ttl": {
                        "type": "integer",
                        "description": "不活跃的时间所能达到最大时长，每次使用缓存均重置不活跃时间为 0。单位为秒(second)",
                        "example": 3600
                    },
                    "truncation_strategy": {
                        "type": "object",
                        "description": "控制历史上下文窗口策略。",
                        "properties": {
                            "type": {
                                "type": "string",
                                "description": "用户截断的策略，支持 `last_history_tokens` 和 `rolling_tokens` 两种，取决于模型版本。",
                                "example": "last_history_tokens"
                            },
                            "last_history_tokens": {
                                "type": "integer",
                                "description": "历史存储的最大 token 数，默认为 4096。根据模型上下文大小对历史存储截断。",
                                "default": 4096,
                                "example": 12000
                            },
                            "rolling_tokens": {
                                "type": "boolean",
                                "description": "历史消息长度超过模型上下文时，是否自动对历史上下文进行裁剪。\n- 若设置为 true，在历史消息长度超过上下文长度时模型自动清除定量历史消息，并重新计算保持的消息。\n- 若设置为 false，在历史消息长度超过上下文长度时模型会停止输出（finish_reason='length'）。",
                                "default": true,
                                "example": true
                            }
                        }
                    },
                    "usage": {
                        "type": "object",
                        "description": "本次请求的 token 消耗情况。",
                        "properties": {
                            "prompt_tokens": {
                                "type": "integer",
                                "description": "输入的 prompt token 数量",
                                "example": 18
                            },
                            "completion_tokens": {
                                "type": "integer",
                                "description": "模型生成的 token 数量",
                                "example": 0
                            },
                            "total_tokens": {
                                "type": "integer",
                                "description": "本次请求消耗的总 token 数量（输入 + 输出）",
                                "example": 18
                            },
                            "prompt_tokens_details": {
                                "type": "object",
                                "description": "prompt tokens 中命中上下文缓存的 tokens 数相关信息",
                                "properties": {
                                    "cached_tokens": {
                                        "type": "integer",
                                        "description": "命中上下文缓存的 tokens 数",
                                        "example": 0
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}